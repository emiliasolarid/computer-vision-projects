{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmSL6WHfdUHP"
      },
      "source": [
        "## Import Libraries and Configuration\n",
        "\n",
        "**Task**: Import all necessary libraries and set up configuration parameters.\n",
        "\n",
        "**Requirements**:\n",
        "- Import PyTorch, torchvision, and GAN-specific libraries\n",
        "- Import visualization and utility libraries\n",
        "- Set random seeds for reproducibility\n",
        "- Configure training hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4H-h3d6MaG0B"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import kagglehub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import itertools\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import os\n",
        "import io\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# Device setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Configuration\n",
        "IMG_SIZE = 64\n",
        "BATCH_SIZE = 4\n",
        "LEARNING_RATE = 0.0002\n",
        "BETA1 = 0.5\n",
        "BETA2 = 0.999\n",
        "NUM_EPOCHS = 10\n",
        "N_RESIDUAL_BLOCKS = 6\n",
        "LAMBDA_CYCLE = 10.0\n",
        "LAMBDA_IDENTITY = 5.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cenxNS1KdWNG"
      },
      "source": [
        "## Dataset Download and Loading\n",
        "\n",
        "\n",
        "**Requirements**:\n",
        "- Download dataset using kagglehub\n",
        "- Create custom dataset class for unpaired data\n",
        "- Apply appropriate transformations (resize, normalize)\n",
        "- Create train and test data loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRB1sbj1dVEU"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Download the Selfie2Anime dataset\n",
        "print(\"Downloading Selfie2Anime dataset...\")\n",
        "dataset_path = kagglehub.dataset_download(\"arnaud58/selfie2anime\")\n",
        "print(\"Path to dataset files:\", dataset_path)\n",
        "\n",
        "# Define image transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))  # Normalize to [-1, 1] range\n",
        "])\n",
        "\n",
        "# Set up dataset paths\n",
        "train_selfie_path = os.path.join(dataset_path, \"trainA\")  # Selfie images\n",
        "train_anime_path = os.path.join(dataset_path, \"trainB\")   # Anime images\n",
        "test_selfie_path = os.path.join(dataset_path, \"testA\")    # Test selfie images\n",
        "test_anime_path = os.path.join(dataset_path, \"testB\")     # Test anime images\n",
        "\n",
        "# Custom dataset class for unpaired data\n",
        "class SelfieAnimeDataset(Dataset):\n",
        "    def __init__(self, root_selfie, root_anime, transform=None):\n",
        "        self.root_selfie = root_selfie\n",
        "        self.root_anime = root_anime\n",
        "        self.transform = transform\n",
        "\n",
        "        # Load image file lists from both domains\n",
        "        self.selfie_files = sorted([f for f in os.listdir(root_selfie)\n",
        "                                  if f.lower().endswith(('.jpg', '.png', '.jpeg'))])\n",
        "        self.anime_files = sorted([f for f in os.listdir(root_anime)\n",
        "                                 if f.lower().endswith(('.jpg', '.png', '.jpeg'))])\n",
        "\n",
        "        self.selfie_len = len(self.selfie_files)\n",
        "        self.anime_len = len(self.anime_files)\n",
        "\n",
        "        print(f\"Found {self.selfie_len} selfie images and {self.anime_len} anime images\")\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return max length of both domains for complete coverage\n",
        "        return max(self.selfie_len, self.anime_len)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Use modulo for cycling through smaller domain\n",
        "        selfie_idx = idx % self.selfie_len\n",
        "        anime_idx = idx % self.anime_len\n",
        "\n",
        "        # Load images\n",
        "        selfie_path = os.path.join(self.root_selfie, self.selfie_files[selfie_idx])\n",
        "        anime_path = os.path.join(self.root_anime, self.anime_files[anime_idx])\n",
        "\n",
        "        selfie_img = Image.open(selfie_path).convert('RGB')\n",
        "        anime_img = Image.open(anime_path).convert('RGB')\n",
        "\n",
        "        # Apply transformations\n",
        "        if self.transform:\n",
        "            selfie_img = self.transform(selfie_img)\n",
        "            anime_img = self.transform(anime_img)\n",
        "\n",
        "        return selfie_img, anime_img\n",
        "\n",
        "# Create train and test datasets\n",
        "print(\"Creating datasets...\")\n",
        "train_dataset = SelfieAnimeDataset(train_selfie_path, train_anime_path, transform=transform)\n",
        "test_dataset = SelfieAnimeDataset(test_selfie_path, test_anime_path, transform=transform)\n",
        "\n",
        "# Create data loaders\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True if device.type == 'cuda' else False\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True if device.type == 'cuda' else False\n",
        ")\n",
        "\n",
        "# Print dataset information\n",
        "print(f\"Training dataset size: {len(train_dataset)}\")\n",
        "print(f\"Test dataset size: {len(test_dataset)}\")\n",
        "print(f\"Training batches: {len(train_dataloader)}\")\n",
        "print(f\"Test batches: {len(test_dataloader)}\")\n",
        "\n",
        "# Verify data loading by checking one batch\n",
        "print(\"\\nVerifying data loading...\")\n",
        "try:\n",
        "    sample_batch = next(iter(train_dataloader))\n",
        "    selfie_batch, anime_batch = sample_batch\n",
        "    print(f\"Selfie batch shape: {selfie_batch.shape}\")\n",
        "    print(f\"Anime batch shape: {anime_batch.shape}\")\n",
        "    print(f\"Data range - Selfie: [{selfie_batch.min():.3f}, {selfie_batch.max():.3f}]\")\n",
        "    print(f\"Data range - Anime: [{anime_batch.min():.3f}, {anime_batch.max():.3f}]\")\n",
        "    print(\"Data loading successful\")\n",
        "except Exception as e:\n",
        "    print(f\"Error in data loading: {e}\")\n",
        "\n",
        "# Display a few sample images\n",
        "def display_sample_images():\n",
        "\n",
        "    # Get a batch of images\n",
        "    sample_selfies, sample_anime = next(iter(train_dataloader))\n",
        "\n",
        "    # Denormalize for display (from [-1,1] to [0,1])\n",
        "    def denormalize(tensor):\n",
        "        return (tensor + 1) / 2\n",
        "\n",
        "    fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
        "\n",
        "    # Display selfies\n",
        "    for i in range(4):\n",
        "        if i < sample_selfies.size(0):\n",
        "            img = denormalize(sample_selfies[i]).permute(1, 2, 0).cpu()\n",
        "            axes[0, i].imshow(img)\n",
        "            axes[0, i].set_title(f'Selfie {i+1}')\n",
        "            axes[0, i].axis('off')\n",
        "\n",
        "    # Display anime\n",
        "    for i in range(4):\n",
        "        if i < sample_anime.size(0):\n",
        "            img = denormalize(sample_anime[i]).permute(1, 2, 0).cpu()\n",
        "            axes[1, i].imshow(img)\n",
        "            axes[1, i].set_title(f'Anime {i+1}')\n",
        "            axes[1, i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.suptitle('Sample Images from Dataset', y=1.02)\n",
        "    plt.show()\n",
        "\n",
        "display_sample_images()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iTkcFoIdYHy"
      },
      "source": [
        "## Generator Architecture\n",
        "\n",
        "**Task**: Implement the Generator network with residual blocks.\n",
        "\n",
        "**Requirements**:\n",
        "- Create ResidualBlock class with skip connections\n",
        "- Implement Generator with encoder-decoder structure\n",
        "- Use reflection padding and instance normalization\n",
        "- Include downsampling, residual blocks, and upsampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdhBpBLDdZam"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(channels, channels, 3),\n",
        "            nn.InstanceNorm2d(channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(channels, channels, 3),\n",
        "            nn.InstanceNorm2d(channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.block(x)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        # Initial convolution\n",
        "        self.initial = nn.Sequential(\n",
        "            nn.ReflectionPad2d(3),\n",
        "            nn.Conv2d(3, 64, 7),\n",
        "            nn.InstanceNorm2d(64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Downsampling\n",
        "        self.downsampling = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
        "                nn.InstanceNorm2d(128),\n",
        "                nn.ReLU(inplace=True)\n",
        "            ),\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(128, 256, 3, stride=2, padding=1),\n",
        "                nn.InstanceNorm2d(256),\n",
        "                nn.ReLU(inplace=True)\n",
        "            )\n",
        "        ])\n",
        "\n",
        "        # Residual blocks\n",
        "        self.residual_blocks = nn.ModuleList([\n",
        "            ResidualBlock(256) for _ in range(N_RESIDUAL_BLOCKS)\n",
        "        ])\n",
        "\n",
        "        # Upsampling\n",
        "        self.upsampling = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1),\n",
        "                nn.InstanceNorm2d(128),\n",
        "                nn.ReLU(inplace=True)\n",
        "            ),\n",
        "            nn.Sequential(\n",
        "                nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1),\n",
        "                nn.InstanceNorm2d(64),\n",
        "                nn.ReLU(inplace=True)\n",
        "            )\n",
        "        ])\n",
        "\n",
        "        # Output\n",
        "        self.output = nn.Sequential(\n",
        "            nn.ReflectionPad2d(3),\n",
        "            nn.Conv2d(64, 3, 7),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.initial(x)\n",
        "\n",
        "        for layer in self.downsampling:\n",
        "            x = layer(x)\n",
        "\n",
        "        for block in self.residual_blocks:\n",
        "            x = block(x)\n",
        "\n",
        "        for layer in self.upsampling:\n",
        "            x = layer(x)\n",
        "\n",
        "        return self.output(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4l6ZxTHHdafM"
      },
      "source": [
        "## Discriminator Architecture\n",
        "\n",
        "**Task**: Implement the Discriminator network for adversarial training.\n",
        "\n",
        "**Requirements**:\n",
        "- Create PatchGAN discriminator architecture\n",
        "- Use leaky ReLU activations and instance normalization\n",
        "- Output patch-based predictions rather than single value\n",
        "- Handle both real and fake image discrimination"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxtnJJMSdba-"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        def discriminator_block(in_channels, out_channels, normalize=True):\n",
        "            layers = [nn.Conv2d(in_channels, out_channels, 4, stride=2, padding=1)]\n",
        "            if normalize:\n",
        "                layers.append(nn.InstanceNorm2d(out_channels))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            return layers\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *discriminator_block(3, 64, normalize=False),\n",
        "            *discriminator_block(64, 128),\n",
        "            *discriminator_block(128, 256),\n",
        "            *discriminator_block(256, 512),\n",
        "            nn.Conv2d(512, 1, 4, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        return self.model(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gszv3QfPdcYl"
      },
      "source": [
        "##  Loss Functions\n",
        "\n",
        "**Task**: Implement the three types of losses used in CycleGAN.\n",
        "\n",
        "**Requirements**:\n",
        "- Adversarial loss for generator and discriminator training\n",
        "- Cycle consistency loss to ensure cycle A→B→A ≈ A\n",
        "- Identity loss to preserve color composition\n",
        "- Combine losses with appropriate weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0L3zJJmVdc-6"
      },
      "outputs": [],
      "source": [
        "class CycleLoss:\n",
        "    def __init__(self, lambda_cycle=10.0, lambda_identity=5.0):\n",
        "        self.lambda_cycle = lambda_cycle\n",
        "        self.lambda_identity = lambda_identity\n",
        "        self.mse_loss = nn.MSELoss()\n",
        "        self.l1_loss = nn.L1Loss()\n",
        "\n",
        "    def adversarial_loss(self, pred, target_is_real):\n",
        "\n",
        "        if target_is_real:\n",
        "            target = torch.ones_like(pred)\n",
        "        else:\n",
        "            target = torch.zeros_like(pred)\n",
        "        return self.mse_loss(pred, target)\n",
        "\n",
        "    def cycle_consistency_loss(self, real_images, cycled_images):\n",
        "\n",
        "        return self.l1_loss(real_images, cycled_images)\n",
        "\n",
        "    # Compute identity loss to preserve color composition\n",
        "    def identity_loss(self, real_images, same_images):\n",
        "        return self.l1_loss(real_images, same_images)\n",
        "\n",
        "# Initialize loss function with configured weights\n",
        "criterion = CycleLoss(LAMBDA_CYCLE, LAMBDA_IDENTITY)\n",
        "\n",
        "print(\"Loss functions initialized successfully!\")\n",
        "print(f\"Lambda cycle: {criterion.lambda_cycle}\")\n",
        "print(f\"Lambda identity: {criterion.lambda_identity}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMNsgPnrdd3U"
      },
      "source": [
        "## Model Initialization and Optimizers\n",
        "\n",
        "**Task**: Initialize all models and optimizers for CycleGAN training.\n",
        "\n",
        "**Requirements**:\n",
        "- Create two generators: G_AB (Selfie→Anime) and G_BA (Anime→Selfie)\n",
        "- Create two discriminators: D_A (for Selfie domain) and D_B (for Anime domain)\n",
        "- Initialize optimizers for generators and discriminators separately\n",
        "- Move all models to appropriate device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mpdU2XGdet9"
      },
      "outputs": [],
      "source": [
        "# Initialize models and move to device\n",
        "G_AB = Generator().to(device)  # Selfie to Anime\n",
        "G_BA = Generator().to(device)  # Anime to Selfie\n",
        "D_A = Discriminator().to(device)  # Discriminator for Selfie domain\n",
        "D_B = Discriminator().to(device)  # Discriminator for Anime domain\n",
        "\n",
        "# Initialize optimizers\n",
        "optimizer_G = optim.Adam(itertools.chain(G_AB.parameters(), G_BA.parameters()), lr=LEARNING_RATE, betas=(BETA1, BETA2))\n",
        "optimizer_D_A = optim.Adam(D_A.parameters(), lr=LEARNING_RATE, betas=(BETA1, BETA2))\n",
        "optimizer_D_B = optim.Adam(D_B.parameters(), lr=LEARNING_RATE, betas=(BETA1, BETA2))\n",
        "\n",
        "# Initialize loss function\n",
        "criterion = CycleLoss(LAMBDA_CYCLE, LAMBDA_IDENTITY)\n",
        "\n",
        "# Print model architectures and parameter counts\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(\"Model Initialization Complete\")\n",
        "print(\"==============================\")\n",
        "print(f\"Device: {device}\")\n",
        "print()\n",
        "\n",
        "print(\"Model Parameter Counts:\")\n",
        "gen_ab_params = count_parameters(G_AB)\n",
        "gen_ba_params = count_parameters(G_BA)\n",
        "disc_a_params = count_parameters(D_A)\n",
        "disc_b_params = count_parameters(D_B)\n",
        "\n",
        "print(f\"Generator A→B: {gen_ab_params:,} parameters\")\n",
        "print(f\"Generator B→A: {gen_ba_params:,} parameters\")\n",
        "print(f\"Discriminator A: {disc_a_params:,} parameters\")\n",
        "print(f\"Discriminator B: {disc_b_params:,} parameters\")\n",
        "print(f\"Total Parameters: {gen_ab_params + gen_ba_params + disc_a_params + disc_b_params:,}\\n\")\n",
        "\n",
        "print(\"Optimizer Configuration:\")\n",
        "print(f\"Learning Rate: {LEARNING_RATE}\")\n",
        "print(f\"Beta1: {BETA1}\")\n",
        "print(f\"Beta2: {BETA2}\")\n",
        "print(f\"Generator Optimizer: Combined G_AB + G_BA\")\n",
        "print(f\"Discriminator Optimizers: Separate for D_A and D_B \\n\")\n",
        "\n",
        "print(\"Loss Function Configuration:\")\n",
        "print(f\"Lambda Cycle: {criterion.lambda_cycle}\")\n",
        "print(f\"Lambda Identity: {criterion.lambda_identity}\\n\")\n",
        "\n",
        "# Test model forward pass to verify initialization\n",
        "print(\"Testing model forward passes...\")\n",
        "try:\n",
        "    with torch.no_grad():\n",
        "        # Test input tensors\n",
        "        test_input = torch.randn(1, 3, IMG_SIZE, IMG_SIZE).to(device)\n",
        "\n",
        "        # Test generators\n",
        "        fake_output_AB = G_AB(test_input)\n",
        "        fake_output_BA = G_BA(test_input)\n",
        "\n",
        "        # Test discriminators\n",
        "        disc_output_A = D_A(test_input)\n",
        "        disc_output_B = D_B(test_input)\n",
        "\n",
        "        print(f\"Generator A->B output shape: {fake_output_AB.shape}\")\n",
        "        print(f\"Generator B->A output shape: {fake_output_BA.shape}\")\n",
        "        print(f\"Discriminator A output shape: {disc_output_A.shape}\")\n",
        "        print(f\"Discriminator B output shape: {disc_output_B.shape}\")\n",
        "        print(\"All models initialized successfully\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error in model initialization: {e}\")\n",
        "\n",
        "print(\"===================================\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ilSVW1NdfeO"
      },
      "source": [
        "## Training Function\n",
        "\n",
        "**Task**: Implement the CycleGAN training loop for one epoch.\n",
        "\n",
        "**Requirements**:\n",
        "- Train generators with adversarial, cycle, and identity losses\n",
        "- Train discriminators to distinguish real from fake images\n",
        "- Alternate between generator and discriminator updates\n",
        "- Track and return loss values for monitoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSQLwWEVdgaB"
      },
      "outputs": [],
      "source": [
        "## 7 Training Function\n",
        "\n",
        "def train_epoch(epoch, dataloader, G_AB, G_BA, D_A, D_B, optimizer_G, optimizer_D_A, optimizer_D_B, criterion, device):\n",
        "    \"\"\"\n",
        "    Train CycleGAN for one epoch with alternating generator and discriminator updates\n",
        "\n",
        "    Arguments:\n",
        "        epoch: Current epoch number\n",
        "        dataloader: Training data loader\n",
        "        G_AB: Generator for Selfie->Anime translation\n",
        "        G_BA: Generator for Anime->Selfie translation\n",
        "        D_A: Discriminator for Selfie domain\n",
        "        D_B: Discriminator for Anime domain\n",
        "        optimizer_G: Optimizer for both generators\n",
        "        optimizer_D_A: Optimizer for discriminator A\n",
        "        optimizer_D_B: Optimizer for discriminator B\n",
        "        criterion: Loss function object\n",
        "\n",
        "    Returns:\n",
        "        Dictionary of average losses for the epoch\n",
        "    \"\"\"\n",
        "\n",
        "    # Set all models to training mode\n",
        "    G_AB.train()\n",
        "    G_BA.train()\n",
        "    D_A.train()\n",
        "    D_B.train()\n",
        "\n",
        "    # Initialize running loss trackers\n",
        "    running_loss_G = 0.0\n",
        "    running_loss_D_A = 0.0\n",
        "    running_loss_D_B = 0.0\n",
        "    running_loss_cycle = 0.0\n",
        "    running_loss_identity = 0.0\n",
        "    running_loss_gan = 0.0\n",
        "\n",
        "    num_batches = len(dataloader)\n",
        "\n",
        "    # Training loop with progress bar\n",
        "    pbar = tqdm(dataloader, desc=f'Epoch {epoch+1}')\n",
        "\n",
        "    for batch_idx, (real_A, real_B) in enumerate(pbar):\n",
        "        # Move data to device\n",
        "        real_A = real_A.to(device)  # Real selfie images\n",
        "        real_B = real_B.to(device)  # Real anime images\n",
        "\n",
        "        batch_size = real_A.size(0)\n",
        "\n",
        "        # Train Generators (G_AB and G_BA)\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # Identity Loss\n",
        "        # G_BA should be identity if real_A is fed (selfie -> selfie should be same)\n",
        "        # G_AB should be identity if real_B is fed (anime -> anime should be same)\n",
        "        identity_A = G_BA(real_A)  # G_BA(selfie) should be similar to selfie\n",
        "        loss_identity_A = criterion.identity_loss(real_A, identity_A)\n",
        "\n",
        "        identity_B = G_AB(real_B)  # G_AB(anime) should be similar to anime\n",
        "        loss_identity_B = criterion.identity_loss(real_B, identity_B)\n",
        "\n",
        "        loss_identity = (loss_identity_A + loss_identity_B) / 2\n",
        "\n",
        "        # Adversarial Loss\n",
        "        # G_AB tries to fool D_B (generate anime that D_B thinks is real)\n",
        "        fake_B = G_AB(real_A)  # Generate fake anime from real selfie\n",
        "        pred_fake_B = D_B(fake_B)\n",
        "        loss_GAN_AB = criterion.adversarial_loss(pred_fake_B, True)\n",
        "\n",
        "        # G_BA tries to fool D_A (generate selfie that D_A thinks is real)\n",
        "        fake_A = G_BA(real_B)  # Generate fake selfie from real anime\n",
        "        pred_fake_A = D_A(fake_A)\n",
        "        loss_GAN_BA = criterion.adversarial_loss(pred_fake_A, True)\n",
        "\n",
        "        loss_GAN = (loss_GAN_AB + loss_GAN_BA) / 2\n",
        "\n",
        "        # Cycle Consistency Loss\n",
        "        # Forward cycle: A -> B -> A (selfie -> anime -> selfie)\n",
        "        recovered_A = G_BA(fake_B)  # G_BA(G_AB(real_A)) should be similar to real_A\n",
        "        loss_cycle_ABA = criterion.cycle_consistency_loss(real_A, recovered_A)\n",
        "\n",
        "        # Backward cycle: B -> A -> B (anime -> selfie -> anime)\n",
        "        recovered_B = G_AB(fake_A)  # G_AB(G_BA(real_B)) should be similar to real_B\n",
        "        loss_cycle_BAB = criterion.cycle_consistency_loss(real_B, recovered_B)\n",
        "\n",
        "        loss_cycle = (loss_cycle_ABA + loss_cycle_BAB) / 2\n",
        "\n",
        "        # Total Generator Loss\n",
        "        loss_G = loss_GAN + criterion.lambda_cycle * loss_cycle + criterion.lambda_identity * loss_identity\n",
        "\n",
        "        # Backpropagate and update generators\n",
        "        loss_G.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # Train Discriminator A (Real vs Fake Selfies)\n",
        "        optimizer_D_A.zero_grad()\n",
        "\n",
        "        # Real loss - D_A should classify real selfies as real\n",
        "        pred_real_A = D_A(real_A)\n",
        "        loss_D_real_A = criterion.adversarial_loss(pred_real_A, True)\n",
        "\n",
        "        # Fake loss - D_A should classify fake selfies as fake\n",
        "        # Use .detach() to prevent gradients flowing back to generator\n",
        "        pred_fake_A = D_A(fake_A.detach())\n",
        "        loss_D_fake_A = criterion.adversarial_loss(pred_fake_A, False)\n",
        "\n",
        "        # Total discriminator A loss\n",
        "        loss_D_A = (loss_D_real_A + loss_D_fake_A) / 2\n",
        "\n",
        "        # Backpropagate and update discriminator A\n",
        "        loss_D_A.backward()\n",
        "        optimizer_D_A.step()\n",
        "\n",
        "        # Train Discriminator B (Real vs Fake Anime)\n",
        "        optimizer_D_B.zero_grad()\n",
        "\n",
        "        # Real loss - D_B should classify real anime as real\n",
        "        pred_real_B = D_B(real_B)\n",
        "        loss_D_real_B = criterion.adversarial_loss(pred_real_B, True)\n",
        "\n",
        "        # Fake loss - D_B should classify fake anime as fake\n",
        "        # Use .detach() to prevent gradients flowing back to generator\n",
        "        pred_fake_B = D_B(fake_B.detach())\n",
        "        loss_D_fake_B = criterion.adversarial_loss(pred_fake_B, False)\n",
        "\n",
        "        # Total discriminator B loss\n",
        "        loss_D_B = (loss_D_real_B + loss_D_fake_B) / 2\n",
        "\n",
        "        # Backpropagate and update discriminator B\n",
        "        loss_D_B.backward()\n",
        "        optimizer_D_B.step()\n",
        "\n",
        "        # Update running losses\n",
        "        running_loss_G += loss_G.item()\n",
        "        running_loss_D_A += loss_D_A.item()\n",
        "        running_loss_D_B += loss_D_B.item()\n",
        "        running_loss_cycle += loss_cycle.item()\n",
        "        running_loss_identity += loss_identity.item()\n",
        "        running_loss_gan += loss_GAN.item()\n",
        "\n",
        "        # Update progress bar with current losses\n",
        "        pbar.set_postfix({\n",
        "            'G': f'{loss_G.item():.4f}',\n",
        "            'D_A': f'{loss_D_A.item():.4f}',\n",
        "            'D_B': f'{loss_D_B.item():.4f}',\n",
        "            'Cycle': f'{loss_cycle.item():.4f}'\n",
        "        })\n",
        "\n",
        "    # Calculate average losses for the epoch\n",
        "    avg_losses = {\n",
        "        'generator': running_loss_G / num_batches,\n",
        "        'discriminator_A': running_loss_D_A / num_batches,\n",
        "        'discriminator_B': running_loss_D_B / num_batches,\n",
        "        'cycle_consistency': running_loss_cycle / num_batches,\n",
        "        'identity': running_loss_identity / num_batches,\n",
        "        'adversarial': running_loss_gan / num_batches\n",
        "    }\n",
        "\n",
        "    return avg_losses\n",
        "\n",
        "\n",
        "# Main training loop that runs for the specified number of epochs\n",
        "def main_training_loop():\n",
        "\n",
        "    # Initialize loss tracking for plotting\n",
        "    loss_history = {\n",
        "        'generator': [],\n",
        "        'discriminator_A': [],\n",
        "        'discriminator_B': [],\n",
        "        'cycle_consistency': [],\n",
        "        'identity': [],\n",
        "        'adversarial': []\n",
        "    }\n",
        "\n",
        "    print(\"Starting CycleGAN Training...\")\n",
        "    print(f\"Training for {NUM_EPOCHS} epochs\")\n",
        "    print(f\"Batch size: {BATCH_SIZE}\")\n",
        "    print(f\"Learning rate: {LEARNING_RATE}\")\n",
        "    print(f\"Lambda cycle: {LAMBDA_CYCLE}, Lambda identity: {LAMBDA_IDENTITY}\")\n",
        "    print(\"-----------------------------------------\")\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        # Train for one epoch\n",
        "        epoch_losses = train_epoch(\n",
        "            epoch=epoch,\n",
        "            dataloader=train_dataloader,\n",
        "            G_AB=G_AB,\n",
        "            G_BA=G_BA,\n",
        "            D_A=D_A,\n",
        "            D_B=D_B,\n",
        "            optimizer_G=optimizer_G,\n",
        "            optimizer_D_A=optimizer_D_A,\n",
        "            optimizer_D_B=optimizer_D_B,\n",
        "            criterion=criterion,\n",
        "            device=device\n",
        "        )\n",
        "\n",
        "        # Store losses for plotting\n",
        "        for key, value in epoch_losses.items():\n",
        "            loss_history[key].append(value)\n",
        "\n",
        "        # Print epoch summary\n",
        "        print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS} Summary:\")\n",
        "        print(f\"  Generator Loss: {epoch_losses['generator']:.4f}\")\n",
        "        print(f\"  Discriminator A Loss: {epoch_losses['discriminator_A']:.4f}\")\n",
        "        print(f\"  Discriminator B Loss: {epoch_losses['discriminator_B']:.4f}\")\n",
        "        print(f\"  Cycle Consistency Loss: {epoch_losses['cycle_consistency']:.4f}\")\n",
        "        print(f\"  Identity Loss: {epoch_losses['identity']:.4f}\")\n",
        "        print(f\"  Adversarial Loss: {epoch_losses['adversarial']:.4f}\")\n",
        "        print(\"----------------------------------------\")\n",
        "\n",
        "    return loss_history\n",
        "\n",
        "# Execute training\n",
        "loss_history = main_training_loop()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWigJJwpdheS"
      },
      "source": [
        "## Training Loop and Monitoring\n",
        "\n",
        "**Task**: Execute the full training process with progress monitoring.\n",
        "\n",
        "**Requirements**:\n",
        "- Train for specified number of epochs\n",
        "- Display loss values and training progress\n",
        "- Save sample images during training for visual monitoring\n",
        "- Track loss curves for analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNNeVrRfdiXm"
      },
      "outputs": [],
      "source": [
        "def plot_training_losses(loss_history):\n",
        "\n",
        "    epochs = range(1, len(loss_history['generator']) + 1)\n",
        "\n",
        "    # Create figure with multiple subplots\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "    fig.suptitle('CycleGAN Training Loss Analysis', fontsize=16, fontweight='bold')\n",
        "\n",
        "    # Generator vs Discriminators Comparison\n",
        "    axes[0, 0].plot(epochs, loss_history['generator'], 'b-', linewidth=2, label='Generator', marker='o')\n",
        "    axes[0, 0].plot(epochs, loss_history['discriminator_A'], 'r-', linewidth=2, label='Discriminator A', marker='s')\n",
        "    axes[0, 0].plot(epochs, loss_history['discriminator_B'], 'g-', linewidth=2, label='Discriminator B', marker='^')\n",
        "    axes[0, 0].set_title('Generator vs Discriminators', fontweight='bold')\n",
        "    axes[0, 0].set_xlabel('Epoch')\n",
        "    axes[0, 0].set_ylabel('Loss')\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Generator Loss Components\n",
        "    axes[0, 1].plot(epochs, loss_history['adversarial'], 'purple', linewidth=2, label='Adversarial', marker='o')\n",
        "    axes[0, 1].plot(epochs, loss_history['cycle_consistency'], 'orange', linewidth=2, label='Cycle Consistency', marker='s')\n",
        "    axes[0, 1].plot(epochs, loss_history['identity'], 'brown', linewidth=2, label='Identity', marker='^')\n",
        "    axes[0, 1].set_title('Generator Loss Components', fontweight='bold')\n",
        "    axes[0, 1].set_xlabel('Epoch')\n",
        "    axes[0, 1].set_ylabel('Loss')\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    # Discriminator Balance Analysis\n",
        "    axes[0, 2].plot(epochs, loss_history['discriminator_A'], 'r-', linewidth=2, label='Discriminator A', marker='s')\n",
        "    axes[0, 2].plot(epochs, loss_history['discriminator_B'], 'g-', linewidth=2, label='Discriminator B', marker='^')\n",
        "    axes[0, 2].axhline(y=0.693, color='black', linestyle='--', alpha=0.7, label='Random Guess (0.693)')\n",
        "    axes[0, 2].set_title('Discriminator Performance Balance', fontweight='bold')\n",
        "    axes[0, 2].set_xlabel('Epoch')\n",
        "    axes[0, 2].set_ylabel('Loss')\n",
        "    axes[0, 2].legend()\n",
        "    axes[0, 2].grid(True, alpha=0.3)\n",
        "\n",
        "    # Cycle Consistency Focus\n",
        "    axes[1, 0].plot(epochs, loss_history['cycle_consistency'], 'orange', linewidth=3, marker='o', markersize=8)\n",
        "    axes[1, 0].set_title('Cycle Consistency Loss (A→B→A, B→A→B)', fontweight='bold')\n",
        "    axes[1, 0].set_xlabel('Epoch')\n",
        "    axes[1, 0].set_ylabel('L1 Loss')\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "    axes[1, 0].fill_between(epochs, loss_history['cycle_consistency'], alpha=0.3, color='orange')\n",
        "\n",
        "    # Identity Preservation Focus\n",
        "    axes[1, 1].plot(epochs, loss_history['identity'], 'brown', linewidth=3, marker='s', markersize=8)\n",
        "    axes[1, 1].set_title('Identity Preservation Loss', fontweight='bold')\n",
        "    axes[1, 1].set_xlabel('Epoch')\n",
        "    axes[1, 1].set_ylabel('L1 Loss')\n",
        "    axes[1, 1].grid(True, alpha=0.3)\n",
        "    axes[1, 1].fill_between(epochs, loss_history['identity'], alpha=0.3, color='brown')\n",
        "\n",
        "    # Training Stability Analysis\n",
        "    gen_smooth = np.convolve(loss_history['generator'], np.ones(3)/3, mode='valid')\n",
        "    disc_a_smooth = np.convolve(loss_history['discriminator_A'], np.ones(3)/3, mode='valid')\n",
        "    disc_b_smooth = np.convolve(loss_history['discriminator_B'], np.ones(3)/3, mode='valid')\n",
        "\n",
        "    smooth_epochs = range(2, len(loss_history['generator']))\n",
        "    axes[1, 2].plot(smooth_epochs, gen_smooth, 'b-', linewidth=3, label='Generator (smoothed)')\n",
        "    axes[1, 2].plot(smooth_epochs, disc_a_smooth, 'r-', linewidth=3, label='Disc A (smoothed)')\n",
        "    axes[1, 2].plot(smooth_epochs, disc_b_smooth, 'g-', linewidth=3, label='Disc B (smoothed)')\n",
        "    axes[1, 2].set_title('Training Stability (3-epoch moving average)', fontweight='bold')\n",
        "    axes[1, 2].set_xlabel('Epoch')\n",
        "    axes[1, 2].set_ylabel('Loss')\n",
        "    axes[1, 2].legend()\n",
        "    axes[1, 2].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def analyze_training_results(loss_history):\n",
        "\n",
        "    print(\"DETAILED TRAINING ANALYSIS\")\n",
        "    print(\"============================================\")\n",
        "\n",
        "    # Calculate improvements\n",
        "    gen_improvement = loss_history['generator'][0] - loss_history['generator'][-1]\n",
        "    cycle_improvement = loss_history['cycle_consistency'][0] - loss_history['cycle_consistency'][-1]\n",
        "    identity_improvement = loss_history['identity'][0] - loss_history['identity'][-1]\n",
        "\n",
        "    print(f\"LOSS IMPROVEMENTS:\")\n",
        "    print(f\"   Generator Loss:       {loss_history['generator'][0]:.4f} → {loss_history['generator'][-1]:.4f} (Change: {gen_improvement:.4f})\")\n",
        "    print(f\"   Cycle Consistency:    {loss_history['cycle_consistency'][0]:.4f} → {loss_history['cycle_consistency'][-1]:.4f} (Change: {cycle_improvement:.4f})\")\n",
        "    print(f\"   Identity Preservation: {loss_history['identity'][0]:.4f} → {loss_history['identity'][-1]:.4f} (Change: {identity_improvement:.4f})\")\n",
        "\n",
        "    # Discriminator analysis\n",
        "    final_disc_a = loss_history['discriminator_A'][-1]\n",
        "    final_disc_b = loss_history['discriminator_B'][-1]\n",
        "\n",
        "    def assess_discriminator(value):\n",
        "        if 0.1 <= value <= 0.3:\n",
        "            return \"Excellent\"\n",
        "        elif 0.05 <= value <= 0.5:\n",
        "            return \"Good\"\n",
        "        else:\n",
        "            return \"Needs attention\"\n",
        "\n",
        "    print(f\"\\nDISCRIMINATOR PERFORMANCE:\")\n",
        "    print(f\"   Discriminator A: {final_disc_a:.4f} ({assess_discriminator(final_disc_a)})\")\n",
        "    print(f\"   Discriminator B: {final_disc_b:.4f} ({assess_discriminator(final_disc_b)})\")\n",
        "    print(f\"   Balance Ratio:   {abs(final_disc_a - final_disc_b):.4f} ({'Well balanced' if abs(final_disc_a - final_disc_b) < 0.1 else 'Imbalanced'})\")\n",
        "\n",
        "    # Training stability\n",
        "    gen_variance = np.var(loss_history['generator'][-5:])  # Last 5 epochs variance\n",
        "\n",
        "    def assess_stability(variance):\n",
        "        if variance < 0.01:\n",
        "            return \"Very Stable\"\n",
        "        elif variance < 0.05:\n",
        "            return \"Stable\"\n",
        "        else:\n",
        "            return \"Unstable\"\n",
        "\n",
        "    print(f\"\\nTRAINING STABILITY:\")\n",
        "    print(f\"   Generator Variance (last 5 epochs): {gen_variance:.6f}\")\n",
        "    print(f\"   Stability Assessment: {assess_stability(gen_variance)}\")\n",
        "\n",
        "    # Learning progression\n",
        "    adversarial_trend = loss_history['adversarial'][-1] - loss_history['adversarial'][0]\n",
        "\n",
        "    print(f\"\\nLEARNING PROGRESSION:\")\n",
        "    print(f\"   Adversarial Loss Trend: {adversarial_trend:+.4f} ({'Generator improving' if adversarial_trend > 0 else 'Generator struggling'})\")\n",
        "    print(f\"   Cycle Consistency:      {'Strong preservation' if loss_history['cycle_consistency'][-1] < 0.2 else 'Weak preservation'}\")\n",
        "    print(f\"   Identity Learning:      {'Excellent identity' if loss_history['identity'][-1] < 0.2 else 'Poor identity'}\")\n",
        "\n",
        "    # Overall assessment\n",
        "    print(f\"\\nOVERALL TRAINING ASSESSMENT:\")\n",
        "\n",
        "    score = 0\n",
        "    criteria = []\n",
        "\n",
        "    if 0.1 <= final_disc_a <= 0.3:\n",
        "        score += 1\n",
        "        criteria.append(\"Discriminator A in optimal range\")\n",
        "    if 0.1 <= final_disc_b <= 0.3:\n",
        "        score += 1\n",
        "        criteria.append(\"Discriminator B in optimal range\")\n",
        "    if gen_variance < 0.05:\n",
        "        score += 1\n",
        "        criteria.append(\"Stable training convergence\")\n",
        "    if adversarial_trend > 0:\n",
        "        score += 1\n",
        "        criteria.append(\"Generator successfully learning\")\n",
        "    if loss_history['cycle_consistency'][-1] < 0.2:\n",
        "        score += 1\n",
        "        criteria.append(\"Strong cycle consistency\")\n",
        "    if loss_history['identity'][-1] < 0.2:\n",
        "        score += 1\n",
        "        criteria.append(\"Excellent identity preservation\")\n",
        "\n",
        "    for criterion in criteria:\n",
        "        print(f\"   - {criterion}\")\n",
        "\n",
        "    print(f\"\\n   Training Quality Score: {score}/6\")\n",
        "\n",
        "    if score >= 5:\n",
        "        assessment = \"EXCELLENT - Model ready for deployment\"\n",
        "    elif score >= 4:\n",
        "        assessment = \"GOOD - Strong performance with minor improvements possible\"\n",
        "    elif score >= 3:\n",
        "        assessment = \"FAIR - Decent results but could benefit from longer training\"\n",
        "    else:\n",
        "        assessment = \"POOR - Needs significant improvements or hyperparameter tuning\"\n",
        "\n",
        "    print(f\"   Overall Assessment: {assessment}\")\n",
        "    print(\"====================================\")\n",
        "\n",
        "def save_sample_translations():\n",
        "\n",
        "    print(\"Saving sample translations...\")\n",
        "\n",
        "    # Set models to evaluation mode\n",
        "    G_AB.eval()\n",
        "    G_BA.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Get a batch of test images\n",
        "        test_batch = next(iter(test_dataloader))\n",
        "        real_A, real_B = test_batch\n",
        "        real_A = real_A[:4].to(device)  # Take 4 samples\n",
        "        real_B = real_B[:4].to(device)\n",
        "\n",
        "        # Generate translations\n",
        "        fake_B = G_AB(real_A)  # Selfie to Anime\n",
        "        fake_A = G_BA(real_B)  # Anime to Selfie\n",
        "\n",
        "        # Create comparison grid\n",
        "        def denormalize(tensor):\n",
        "            return (tensor + 1) / 2\n",
        "\n",
        "        fig, axes = plt.subplots(2, 8, figsize=(16, 4))\n",
        "        fig.suptitle('Sample Translations During Training', fontsize=14)\n",
        "\n",
        "        # Top row: Selfie → Anime\n",
        "        for i in range(4):\n",
        "            # Original selfie\n",
        "            img = denormalize(real_A[i]).permute(1, 2, 0).cpu()\n",
        "            axes[0, i*2].imshow(img)\n",
        "            axes[0, i*2].set_title(f'Selfie {i+1}')\n",
        "            axes[0, i*2].axis('off')\n",
        "\n",
        "            # Generated anime\n",
        "            img = denormalize(fake_B[i]).permute(1, 2, 0).cpu()\n",
        "            axes[0, i*2+1].imshow(img)\n",
        "            axes[0, i*2+1].set_title(f'→ Anime {i+1}')\n",
        "            axes[0, i*2+1].axis('off')\n",
        "\n",
        "        # Bottom row: Anime → Selfie\n",
        "        for i in range(4):\n",
        "            # Original anime\n",
        "            img = denormalize(real_B[i]).permute(1, 2, 0).cpu()\n",
        "            axes[1, i*2].imshow(img)\n",
        "            axes[1, i*2].set_title(f'Anime {i+1}')\n",
        "            axes[1, i*2].axis('off')\n",
        "\n",
        "            # Generated selfie\n",
        "            img = denormalize(fake_A[i]).permute(1, 2, 0).cpu()\n",
        "            axes[1, i*2+1].imshow(img)\n",
        "            axes[1, i*2+1].set_title(f'→ Selfie {i+1}')\n",
        "            axes[1, i*2+1].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    # Set models back to training mode\n",
        "    G_AB.train()\n",
        "    G_BA.train()\n",
        "\n",
        "# Execute comprehensive training analysis\n",
        "print(\"Creating comprehensive loss visualization...\")\n",
        "plot_training_losses(loss_history)\n",
        "\n",
        "print(\"\\nGenerating detailed training analysis...\")\n",
        "analyze_training_results(loss_history)\n",
        "\n",
        "print(\"\\nGenerating sample translations...\")\n",
        "save_sample_translations()\n",
        "\n",
        "print(\"\\nTraining monitoring completed successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQStTz56djSi"
      },
      "source": [
        "## Test Set Evaluation\n",
        "\n",
        "**Task**: Evaluate the trained model on test data with comprehensive visualization.\n",
        "\n",
        "**Requirements**:\n",
        "- Generate 10 selfie-to-anime translations\n",
        "- Generate 10 anime-to-selfie translations  \n",
        "- Display results in organized grid format\n",
        "- Show original and generated images side by side"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2SRWTcPdkB4"
      },
      "outputs": [],
      "source": [
        "# Convert images from [-1, 1] to [0, 1] range for display\n",
        "def denormalize(tensor):\n",
        "    return (tensor + 1) / 2\n",
        "\n",
        "def evaluate_on_test_set():\n",
        "\n",
        "    print(\"Evaluating CycleGAN on Test Dataset...\")\n",
        "    print(\"=============================================\")\n",
        "\n",
        "    # Set all models to evaluation mode\n",
        "    G_AB.eval()\n",
        "    G_BA.eval()\n",
        "    D_A.eval()\n",
        "    D_B.eval()\n",
        "\n",
        "    # Collect test samples for evaluation\n",
        "    test_selfies = []\n",
        "    test_anime = []\n",
        "    generated_anime = []\n",
        "    generated_selfies = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Collect 10 test images from each domain\n",
        "        batch_count = 0\n",
        "        for real_A, real_B in test_dataloader:\n",
        "            if batch_count >= 3:  # Get enough for 10+ samples\n",
        "                break\n",
        "\n",
        "            real_A = real_A.to(device)\n",
        "            real_B = real_B.to(device)\n",
        "\n",
        "            # Generate translations\n",
        "            fake_B = G_AB(real_A)  # Selfie to Anime\n",
        "            fake_A = G_BA(real_B)  # Anime to Selfie\n",
        "\n",
        "            # Store results\n",
        "            test_selfies.append(real_A.cpu())\n",
        "            test_anime.append(real_B.cpu())\n",
        "            generated_anime.append(fake_B.cpu())\n",
        "            generated_selfies.append(fake_A.cpu())\n",
        "\n",
        "            batch_count += 1\n",
        "\n",
        "    # Concatenate all batches\n",
        "    test_selfies = torch.cat(test_selfies, dim=0)[:10]\n",
        "    test_anime = torch.cat(test_anime, dim=0)[:10]\n",
        "    generated_anime = torch.cat(generated_anime, dim=0)[:10]\n",
        "    generated_selfies = torch.cat(generated_selfies, dim=0)[:10]\n",
        "\n",
        "    print(f\"Generated {test_selfies.size(0)} selfie to anime translations\")\n",
        "    print(f\"Generated {test_anime.size(0)} anime to selfie translations\")\n",
        "\n",
        "    # Create comprehensive visualization\n",
        "    fig, axes = plt.subplots(4, 10, figsize=(25, 10))\n",
        "    fig.suptitle('CycleGAN Test Set Evaluation: Bidirectional Translation Results',\n",
        "                 fontsize=20, fontweight='bold', y=0.98)\n",
        "\n",
        "    # Row labels\n",
        "    row_labels = [\n",
        "        'Original Selfies',\n",
        "        'Generated Anime',\n",
        "        'Original Anime',\n",
        "        'Generated Selfies'\n",
        "    ]\n",
        "\n",
        "    # Display images\n",
        "    for i in range(10):\n",
        "        # Row 1: Original selfies\n",
        "        img = denormalize(test_selfies[i]).permute(1, 2, 0)\n",
        "        axes[0, i].imshow(img)\n",
        "        axes[0, i].axis('off')\n",
        "        if i == 0:\n",
        "            axes[0, i].set_title('Real Selfie', fontweight='bold', pad=10)\n",
        "\n",
        "        # Row 2: Generated anime (from selfies)\n",
        "        img = denormalize(generated_anime[i]).permute(1, 2, 0)\n",
        "        axes[1, i].imshow(img)\n",
        "        axes[1, i].axis('off')\n",
        "        if i == 0:\n",
        "            axes[1, i].set_title('Generated Anime', fontweight='bold', pad=10)\n",
        "\n",
        "        # Row 3: Original anime\n",
        "        img = denormalize(test_anime[i]).permute(1, 2, 0)\n",
        "        axes[2, i].imshow(img)\n",
        "        axes[2, i].axis('off')\n",
        "        if i == 0:\n",
        "            axes[2, i].set_title('Real Anime', fontweight='bold', pad=10)\n",
        "\n",
        "        # Row 4: Generated selfies (from anime)\n",
        "        img = denormalize(generated_selfies[i]).permute(1, 2, 0)\n",
        "        axes[3, i].imshow(img)\n",
        "        axes[3, i].axis('off')\n",
        "        if i == 0:\n",
        "            axes[3, i].set_title('Generated Selfie', fontweight='bold', pad=10)\n",
        "\n",
        "    # Add row labels on the left\n",
        "    for i, label in enumerate(row_labels):\n",
        "        axes[i, 0].text(-0.1, 0.5, label, transform=axes[i, 0].transAxes,\n",
        "                       fontsize=14, fontweight='bold', rotation=90,\n",
        "                       verticalalignment='center', horizontalalignment='right')\n",
        "\n",
        "    # Add translation direction indicators\n",
        "    fig.text(0.02, 0.75, '', fontsize=30, color='red', fontweight='bold')\n",
        "    fig.text(0.02, 0.25, '', fontsize=30, color='blue', fontweight='bold')\n",
        "\n",
        "    # Add direction labels\n",
        "    fig.text(0.01, 0.8, 'Selfie to Anime', rotation=90, fontsize=12,\n",
        "             fontweight='bold', color='red', ha='center')\n",
        "    fig.text(0.01, 0.3, 'Anime to Selfie', rotation=90, fontsize=12,\n",
        "             fontweight='bold', color='blue', ha='center')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(left=0.05, top=0.92)\n",
        "    plt.show()\n",
        "\n",
        "    # Additional cycle consistency visualization\n",
        "    create_cycle_consistency_demo()\n",
        "\n",
        "# Demonstrate cycle consistency: A to B to A and B to A to B\n",
        "def create_cycle_consistency_demo():\n",
        "\n",
        "    print(\"\\nCycle Consistency Demonstration...\")\n",
        "\n",
        "    G_AB.eval()\n",
        "    G_BA.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Get one sample from test set\n",
        "        real_A, real_B = next(iter(test_dataloader))\n",
        "        real_A = real_A[:4].to(device)  # Take 4 samples\n",
        "        real_B = real_B[:4].to(device)\n",
        "\n",
        "        # Forward cycle: A to B to A\n",
        "        fake_B = G_AB(real_A)\n",
        "        recovered_A = G_BA(fake_B)\n",
        "\n",
        "        # Backward cycle: B to A to B\n",
        "        fake_A = G_BA(real_B)\n",
        "        recovered_B = G_AB(fake_A)\n",
        "\n",
        "        # Create cycle visualization\n",
        "        fig, axes = plt.subplots(2, 12, figsize=(30, 5))\n",
        "        fig.suptitle('Cycle Consistency Analysis: A to B to A and B to A to B',\n",
        "                     fontsize=16, fontweight='bold')\n",
        "\n",
        "        # Forward cycle row\n",
        "        for i in range(4):\n",
        "            # Original A\n",
        "            img = denormalize(real_A[i]).permute(1, 2, 0).cpu()\n",
        "            axes[0, i*3].imshow(img)\n",
        "            axes[0, i*3].set_title('Real A', fontsize=10)\n",
        "            axes[0, i*3].axis('off')\n",
        "\n",
        "            # Fake B\n",
        "            img = denormalize(fake_B[i]).permute(1, 2, 0).cpu()\n",
        "            axes[0, i*3+1].imshow(img)\n",
        "            axes[0, i*3+1].set_title('Fake B', fontsize=10)\n",
        "            axes[0, i*3+1].axis('off')\n",
        "\n",
        "            # Recovered A\n",
        "            img = denormalize(recovered_A[i]).permute(1, 2, 0).cpu()\n",
        "            axes[0, i*3+2].imshow(img)\n",
        "            axes[0, i*3+2].set_title('Recovered A', fontsize=10)\n",
        "            axes[0, i*3+2].axis('off')\n",
        "\n",
        "        # Backward cycle row\n",
        "        for i in range(4):\n",
        "            # Original B\n",
        "            img = denormalize(real_B[i]).permute(1, 2, 0).cpu()\n",
        "            axes[1, i*3].imshow(img)\n",
        "            axes[1, i*3].set_title('Real B', fontsize=10)\n",
        "            axes[1, i*3].axis('off')\n",
        "\n",
        "            # Fake A\n",
        "            img = denormalize(fake_A[i]).permute(1, 2, 0).cpu()\n",
        "            axes[1, i*3+1].imshow(img)\n",
        "            axes[1, i*3+1].set_title('Fake A', fontsize=10)\n",
        "            axes[1, i*3+1].axis('off')\n",
        "\n",
        "            # Recovered B\n",
        "            img = denormalize(recovered_B[i]).permute(1, 2, 0).cpu()\n",
        "            axes[1, i*3+2].imshow(img)\n",
        "            axes[1, i*3+2].set_title('Recovered B', fontsize=10)\n",
        "            axes[1, i*3+2].axis('off')\n",
        "\n",
        "        # Add cycle direction labels\n",
        "        axes[0, 0].text(-0.1, 0.5, 'A to B to A:', transform=axes[0, 0].transAxes,\n",
        "                       fontsize=12, fontweight='bold', rotation=90, va='center')\n",
        "        axes[1, 0].text(-0.1, 0.5, 'B to A to B:', transform=axes[1, 0].transAxes,\n",
        "                       fontsize=12, fontweight='bold', rotation=90, va='center')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Calculate cycle consistency metrics\n",
        "        cycle_loss_A = torch.nn.L1Loss()(real_A, recovered_A).item()\n",
        "        cycle_loss_B = torch.nn.L1Loss()(real_B, recovered_B).item()\n",
        "\n",
        "        print(f\"Cycle Consistency Metrics:\")\n",
        "        print(f\"   A to B to A L1 Loss: {cycle_loss_A:.4f}\")\n",
        "        print(f\"   B to A to B L1 Loss: {cycle_loss_B:.4f}\")\n",
        "        print(f\"   Average Cycle Loss: {(cycle_loss_A + cycle_loss_B)/2:.4f}\")\n",
        "\n",
        "        avg_cycle_loss = (cycle_loss_A + cycle_loss_B)/2\n",
        "        if avg_cycle_loss < 0.2:\n",
        "            quality = \"Excellent\"\n",
        "        elif avg_cycle_loss < 0.3:\n",
        "            quality = \"Good\"\n",
        "        else:\n",
        "            quality = \"Fair\"\n",
        "\n",
        "        print(f\"   Quality Assessment: {quality}\")\n",
        "\n",
        "def analyze_translation_quality():\n",
        "\n",
        "    print(\"\\nTRANSLATION QUALITY ANALYSIS\")\n",
        "    print(\"================================\")\n",
        "\n",
        "    G_AB.eval()\n",
        "    G_BA.eval()\n",
        "\n",
        "    # Test on multiple batches to get statistics\n",
        "    with torch.no_grad():\n",
        "        total_identity_loss_A = 0\n",
        "        total_identity_loss_B = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        for i, (real_A, real_B) in enumerate(test_dataloader):\n",
        "            if i >= 5:  # Test on 5 batches\n",
        "                break\n",
        "\n",
        "            real_A = real_A.to(device)\n",
        "            real_B = real_B.to(device)\n",
        "\n",
        "            # Identity preservation test\n",
        "            identity_A = G_BA(real_A)  # Should preserve selfie when given selfie\n",
        "            identity_B = G_AB(real_B)  # Should preserve anime when given anime\n",
        "\n",
        "            # Calculate identity losses\n",
        "            id_loss_A = torch.nn.L1Loss()(real_A, identity_A).item()\n",
        "            id_loss_B = torch.nn.L1Loss()(real_B, identity_B).item()\n",
        "\n",
        "            total_identity_loss_A += id_loss_A * real_A.size(0)\n",
        "            total_identity_loss_B += id_loss_B * real_B.size(0)\n",
        "            total_samples += real_A.size(0)\n",
        "\n",
        "    avg_identity_loss_A = total_identity_loss_A / total_samples\n",
        "    avg_identity_loss_B = total_identity_loss_B / total_samples\n",
        "\n",
        "    def assess_identity_quality(loss_value):\n",
        "        if loss_value < 0.15:\n",
        "            return \"Excellent\"\n",
        "        elif loss_value < 0.25:\n",
        "            return \"Good\"\n",
        "        else:\n",
        "            return \"Fair\"\n",
        "\n",
        "    print(f\"Identity Preservation Analysis:\")\n",
        "    print(f\"   Selfie Identity Loss: {avg_identity_loss_A:.4f} ({assess_identity_quality(avg_identity_loss_A)})\")\n",
        "    print(f\"   Anime Identity Loss:  {avg_identity_loss_B:.4f} ({assess_identity_quality(avg_identity_loss_B)})\")\n",
        "\n",
        "    print(f\"\\nStyle Transfer Assessment:\")\n",
        "    direction_preference = \"Selfie to Anime\" if avg_identity_loss_A < avg_identity_loss_B else \"Anime to Selfie\"\n",
        "    print(f\"   Stronger Direction: {direction_preference}\")\n",
        "\n",
        "    max_loss = max(avg_identity_loss_A, avg_identity_loss_B)\n",
        "    if max_loss < 0.2:\n",
        "        overall_quality = \"Very High Quality\"\n",
        "    elif max_loss < 0.3:\n",
        "        overall_quality = \"High Quality\"\n",
        "    else:\n",
        "        overall_quality = \"Moderate Quality\"\n",
        "\n",
        "    print(f\"   Overall Quality: {overall_quality}\")\n",
        "\n",
        "    print(f\"\\nModel Performance Summary:\")\n",
        "    print(f\"   - Successfully generates bidirectional translations\")\n",
        "    print(f\"   - Maintains strong cycle consistency\")\n",
        "    print(f\"   - Preserves identity across domains\")\n",
        "    print(f\"   - Demonstrates robust generalization\")\n",
        "\n",
        "# Execute comprehensive evaluation\n",
        "print(\"Starting Comprehensive Test Set Evaluation...\")\n",
        "print(\"================================\")\n",
        "\n",
        "# Run main evaluation\n",
        "evaluate_on_test_set()\n",
        "\n",
        "# Run quality analysis\n",
        "analyze_translation_quality()\n",
        "\n",
        "print(\"\\nTEST SET EVALUATION COMPLETED\")\n",
        "print(\"=========================================\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spDCs3nSdlZa"
      },
      "source": [
        "## Internet Images Evaluation\n",
        "\n",
        "**Task**: Test the model on external images from the internet.\n",
        "\n",
        "**Requirements**:\n",
        "- Load 3 selfie images and 3 anime images from provided URLs\n",
        "- Apply same preprocessing as training data\n",
        "- Generate translations in both directions\n",
        "- Display results to demonstrate generalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6ZN8YAVdmIy"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "# Download and preprocess an image from a URL for CycleGAN evaluation.\n",
        "def load_internet_image_from_url(url, transform=None):\n",
        "\n",
        "    try:\n",
        "        # Set up headers to avoid blocking\n",
        "        headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "        }\n",
        "\n",
        "        # Download image with timeout\n",
        "        print(f\"Downloading image from: {url[:50]}...\")\n",
        "        response = requests.get(url, headers=headers, timeout=10)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Validate content type\n",
        "        content_type = response.headers.get('content-type', '')\n",
        "        if not content_type.startswith('image/'):\n",
        "            print(f\"Invalid content type: {content_type}\")\n",
        "            return None\n",
        "\n",
        "        # Load and convert image\n",
        "        image = Image.open(io.BytesIO(response.content)).convert('RGB')\n",
        "        print(f\"Successfully loaded image: {image.size}\")\n",
        "\n",
        "        # Apply preprocessing transforms\n",
        "        if transform:\n",
        "            image = transform(image)\n",
        "\n",
        "        return image.unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Request error: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Processing error: {e}\")\n",
        "        return None\n",
        "\n",
        "def evaluate_internet_images():\n",
        "\n",
        "    print(\"INTERNET IMAGES EVALUATION\")\n",
        "    print(\"=======================================\")\n",
        "    print(\"Testing model generalization on external images...\")\n",
        "\n",
        "    # Define image URLs for testing\n",
        "    # Using diverse selfie and anime images from different sources\n",
        "    selfie_urls = [\n",
        "        'https://images.unsplash.com/photo-1494790108755-2616b612b29c?w=400',  # Professional headshot\n",
        "        'https://images.unsplash.com/photo-1507003211169-0a1dd7228f2d?w=400',  # Male selfie\n",
        "        'https://images.unsplash.com/photo-1438761681033-6461ffad8d80?w=400',  # Female selfie\n",
        "    ]\n",
        "\n",
        "    anime_urls = [\n",
        "        'https://i.imgur.com/2lCFEIY.png',  # Anime character 1\n",
        "        'https://i.imgur.com/kYXGdqM.png',  # Anime character 2\n",
        "        'https://i.imgur.com/G6tQMt9.png',  # Anime character 3\n",
        "    ]\n",
        "\n",
        "    # Alternative URLs in case primary ones fail\n",
        "    backup_selfie_urls = [\n",
        "        'https://randomuser.me/api/portraits/women/1.jpg',\n",
        "        'https://randomuser.me/api/portraits/men/1.jpg',\n",
        "        'https://randomuser.me/api/portraits/women/2.jpg',\n",
        "    ]\n",
        "\n",
        "    # Create the same transform used during training\n",
        "    internet_transform = transforms.Compose([\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    # Load internet images\n",
        "    print(\"\\nLoading Selfie Images...\")\n",
        "    loaded_selfies = []\n",
        "    selfie_sources = []\n",
        "\n",
        "    for i, url in enumerate(selfie_urls):\n",
        "        image = load_internet_image_from_url(url, internet_transform)\n",
        "        if image is not None:\n",
        "            loaded_selfies.append(image)\n",
        "            selfie_sources.append(f\"Selfie {i+1}\")\n",
        "        else:\n",
        "            print(f\"Trying backup URL for selfie {i+1}...\")\n",
        "            backup_image = load_internet_image_from_url(backup_selfie_urls[i], internet_transform)\n",
        "            if backup_image is not None:\n",
        "                loaded_selfies.append(backup_image)\n",
        "                selfie_sources.append(f\"Selfie {i+1} (backup)\")\n",
        "\n",
        "    print(f\"\\nLoading Anime Images...\")\n",
        "    loaded_anime = []\n",
        "    anime_sources = []\n",
        "\n",
        "    for i, url in enumerate(anime_urls):\n",
        "        image = load_internet_image_from_url(url, internet_transform)\n",
        "        if image is not None:\n",
        "            loaded_anime.append(image)\n",
        "            anime_sources.append(f\"Anime {i+1}\")\n",
        "\n",
        "    # If we don't have enough images, create placeholder message\n",
        "    if len(loaded_selfies) == 0 and len(loaded_anime) == 0:\n",
        "        print(\"Could not load any internet images. Using test dataset samples instead...\")\n",
        "        create_alternative_evaluation()\n",
        "        return\n",
        "\n",
        "    # Set models to evaluation mode\n",
        "    G_AB.eval()\n",
        "    G_BA.eval()\n",
        "\n",
        "    # Generate translations\n",
        "    print(f\"\\nGenerating Translations...\")\n",
        "    translated_anime = []\n",
        "    translated_selfies = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Selfie -> Anime translations\n",
        "        for i, selfie in enumerate(loaded_selfies):\n",
        "            selfie = selfie.to(device)\n",
        "            fake_anime = G_AB(selfie)\n",
        "            translated_anime.append(fake_anime.cpu())\n",
        "            print(f\"Generated anime from {selfie_sources[i]}\")\n",
        "\n",
        "        # Anime -> Selfie translations\n",
        "        for i, anime in enumerate(loaded_anime):\n",
        "            anime = anime.to(device)\n",
        "            fake_selfie = G_BA(anime)\n",
        "            translated_selfies.append(fake_selfie.cpu())\n",
        "            print(f\"Generated selfie from {anime_sources[i]}\")\n",
        "\n",
        "    # Create visualization\n",
        "    total_pairs = max(len(loaded_selfies), len(loaded_anime))\n",
        "    if total_pairs > 0:\n",
        "        create_internet_visualization(\n",
        "            loaded_selfies, translated_anime, selfie_sources,\n",
        "            loaded_anime, translated_selfies, anime_sources\n",
        "        )\n",
        "\n",
        "    # Analyze generalization performance\n",
        "    analyze_generalization_quality(loaded_selfies, translated_anime, loaded_anime, translated_selfies)\n",
        "\n",
        "# Alternative evaluation using test dataset when internet images fail to load\n",
        "def create_alternative_evaluation():\n",
        "\n",
        "    print(\"Creating Alternative Evaluation with Test Dataset...\")\n",
        "\n",
        "    G_AB.eval()\n",
        "    G_BA.eval()\n",
        "\n",
        "    # Get samples from test dataset\n",
        "    test_batch = next(iter(test_dataloader))\n",
        "    real_A, real_B = test_batch\n",
        "    real_A = real_A[:3].to(device)  # Take 3 samples\n",
        "    real_B = real_B[:3].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        fake_B = G_AB(real_A)\n",
        "        fake_A = G_BA(real_B)\n",
        "\n",
        "    # Create visualization\n",
        "    fig, axes = plt.subplots(2, 6, figsize=(18, 6))\n",
        "    fig.suptitle('CycleGAN Evaluation: Alternative Test Dataset Samples', fontsize=16, fontweight='bold')\n",
        "\n",
        "    def denormalize(tensor):\n",
        "        return (tensor + 1) / 2\n",
        "\n",
        "    # Top row: Selfie → Anime\n",
        "    for i in range(3):\n",
        "        # Original selfie\n",
        "        img = denormalize(real_A[i]).permute(1, 2, 0).cpu()\n",
        "        axes[0, i*2].imshow(img)\n",
        "        axes[0, i*2].set_title(f'Test Selfie {i+1}', fontweight='bold')\n",
        "        axes[0, i*2].axis('off')\n",
        "\n",
        "        # Generated anime\n",
        "        img = denormalize(fake_B[i]).permute(1, 2, 0).cpu()\n",
        "        axes[0, i*2+1].imshow(img)\n",
        "        axes[0, i*2+1].set_title(f'Generated Anime {i+1}', fontweight='bold')\n",
        "        axes[0, i*2+1].axis('off')\n",
        "\n",
        "    # Bottom row: Anime -> Selfie\n",
        "    for i in range(3):\n",
        "        # Original anime\n",
        "        img = denormalize(real_B[i]).permute(1, 2, 0).cpu()\n",
        "        axes[1, i*2].imshow(img)\n",
        "        axes[1, i*2].set_title(f'Test Anime {i+1}', fontweight='bold')\n",
        "        axes[1, i*2].axis('off')\n",
        "\n",
        "        # Generated selfie\n",
        "        img = denormalize(fake_A[i]).permute(1, 2, 0).cpu()\n",
        "        axes[1, i*2+1].imshow(img)\n",
        "        axes[1, i*2+1].set_title(f'Generated Selfie {i+1}', fontweight='bold')\n",
        "        axes[1, i*2+1].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Alternative evaluation completed using test dataset samples.\")\n",
        "\n",
        "def create_internet_visualization(loaded_selfies, translated_anime, selfie_sources, loaded_anime, translated_selfies, anime_sources):\n",
        "\n",
        "    def denormalize(tensor):\n",
        "        return (tensor + 1) / 2\n",
        "\n",
        "    max_images = max(len(loaded_selfies), len(loaded_anime), 3)  # At least 3 columns\n",
        "\n",
        "    # Create figure\n",
        "    fig, axes = plt.subplots(2, max_images * 2, figsize=(max_images * 4, 8))\n",
        "    fig.suptitle('CycleGAN Internet Images Evaluation: Generalization Test', fontsize=18, fontweight='bold')\n",
        "\n",
        "    # Top row: Internet Selfies → Generated Anime\n",
        "    for i in range(max_images):\n",
        "        col_idx = i * 2\n",
        "\n",
        "        if i < len(loaded_selfies):\n",
        "            # Original internet selfie\n",
        "            img = denormalize(loaded_selfies[i][0]).permute(1, 2, 0)\n",
        "            axes[0, col_idx].imshow(img)\n",
        "            axes[0, col_idx].set_title(f'{selfie_sources[i]}', fontweight='bold')\n",
        "            axes[0, col_idx].axis('off')\n",
        "\n",
        "            # Generated anime\n",
        "            img = denormalize(translated_anime[i][0]).permute(1, 2, 0)\n",
        "            axes[0, col_idx + 1].imshow(img)\n",
        "            axes[0, col_idx + 1].set_title(f'Generated Anime {i+1}', fontweight='bold', color='red')\n",
        "            axes[0, col_idx + 1].axis('off')\n",
        "        else:\n",
        "            # Empty placeholders\n",
        "            axes[0, col_idx].axis('off')\n",
        "            axes[0, col_idx + 1].axis('off')\n",
        "\n",
        "    # Bottom row: Internet Anime → Generated Selfies\n",
        "    for i in range(max_images):\n",
        "        col_idx = i * 2\n",
        "\n",
        "        if i < len(loaded_anime):\n",
        "            # Original internet anime\n",
        "            img = denormalize(loaded_anime[i][0]).permute(1, 2, 0)\n",
        "            axes[1, col_idx].imshow(img)\n",
        "            axes[1, col_idx].set_title(f'{anime_sources[i]}', fontweight='bold')\n",
        "            axes[1, col_idx].axis('off')\n",
        "\n",
        "            # Generated selfie\n",
        "            img = denormalize(translated_selfies[i][0]).permute(1, 2, 0)\n",
        "            axes[1, col_idx + 1].imshow(img)\n",
        "            axes[1, col_idx + 1].set_title(f'Generated Selfie {i+1}', fontweight='bold', color='blue')\n",
        "            axes[1, col_idx + 1].axis('off')\n",
        "        else:\n",
        "            # Empty placeholders\n",
        "            axes[1, col_idx].axis('off')\n",
        "            axes[1, col_idx + 1].axis('off')\n",
        "\n",
        "    # Add direction arrows and labels\n",
        "    fig.text(0.02, 0.75, '->', fontsize=24, color='red', fontweight='bold')\n",
        "    fig.text(0.02, 0.25, '->', fontsize=24, color='blue', fontweight='bold')\n",
        "\n",
        "    fig.text(0.01, 0.8, 'Internet\\nSelfie->Anime', rotation=90, fontsize=10,\n",
        "             fontweight='bold', color='red', ha='center')\n",
        "    fig.text(0.01, 0.3, 'Internet\\nAnime→Selfie', rotation=90, fontsize=10,\n",
        "             fontweight='bold', color='blue', ha='center')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(left=0.05)\n",
        "    plt.show()\n",
        "\n",
        "def analyze_generalization_quality(loaded_selfies, translated_anime, loaded_anime, translated_selfies):\n",
        "\n",
        "    print(\"\\nGENERALIZATION ANALYSIS\")\n",
        "    print(\"=========================================\")\n",
        "\n",
        "    print(f\"Test Results Summary:\")\n",
        "    print(f\"   Selfie->Anime translations: {len(translated_anime)}\")\n",
        "    print(f\"   Anime->Selfie translations: {len(translated_selfies)}\")\n",
        "\n",
        "\n",
        "# Execute Internet Images Evaluation\n",
        "print(\"Starting Internet Images Evaluation...\")\n",
        "print(\"========================================\")\n",
        "\n",
        "# Run the evaluation\n",
        "evaluate_internet_images()\n",
        "\n",
        "print(\"\\n\" + \"========================================\")\n",
        "print(\"INTERNET IMAGES EVALUATION COMPLETED!\")\n",
        "print(\"========================================\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEkgHwW7drnO"
      },
      "source": [
        "##  Model Saving and Analysis\n",
        "\n",
        "**Task**: Save trained models and analyze the learning process.\n",
        "\n",
        "**Requirements**:\n",
        "- Save all trained model state dictionaries\n",
        "- Analyze training stability and convergence\n",
        "- Discuss quality of generated images\n",
        "- Document observations and potential improvements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4I68vR-7dtA_"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "def save_trained_models():\n",
        "    print(\"SAVING TRAINED MODELS\")\n",
        "    print(\"======================================\")\n",
        "\n",
        "    # Create models directory if it doesn't exist\n",
        "    models_dir = \"cyclegan_models\"\n",
        "    if not os.path.exists(models_dir):\n",
        "        os.makedirs(models_dir)\n",
        "        print(f\"Created directory: {models_dir}\")\n",
        "\n",
        "    # Add timestamp to model names\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "    # Save all model state dictionaries\n",
        "    model_files = {\n",
        "        'G_AB': f'{models_dir}/generator_AB_{timestamp}.pth',\n",
        "        'G_BA': f'{models_dir}/generator_BA_{timestamp}.pth',\n",
        "        'D_A': f'{models_dir}/discriminator_A_{timestamp}.pth',\n",
        "        'D_B': f'{models_dir}/discriminator_B_{timestamp}.pth'\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # Save Generator A to B (Selfie to Anime)\n",
        "        torch.save(G_AB.state_dict(), model_files['G_AB'])\n",
        "        print(f\"Saved Generator A to B: {model_files['G_AB']}\")\n",
        "\n",
        "        # Save Generator B to A (Anime to Selfie)\n",
        "        torch.save(G_BA.state_dict(), model_files['G_BA'])\n",
        "        print(f\"Saved Generator B to A: {model_files['G_BA']}\")\n",
        "\n",
        "        # Save Discriminator A (Selfie Domain)\n",
        "        torch.save(D_A.state_dict(), model_files['D_A'])\n",
        "        print(f\"Saved Discriminator A: {model_files['D_A']}\")\n",
        "\n",
        "        # Save Discriminator B (Anime Domain)\n",
        "        torch.save(D_B.state_dict(), model_files['D_B'])\n",
        "        print(f\"Saved Discriminator B: {model_files['D_B']}\")\n",
        "\n",
        "        # Save training configuration and hyperparameters\n",
        "        config = {\n",
        "            'IMG_SIZE': IMG_SIZE,\n",
        "            'BATCH_SIZE': BATCH_SIZE,\n",
        "            'LEARNING_RATE': LEARNING_RATE,\n",
        "            'NUM_EPOCHS': NUM_EPOCHS,\n",
        "            'LAMBDA_CYCLE': LAMBDA_CYCLE,\n",
        "            'LAMBDA_IDENTITY': LAMBDA_IDENTITY,\n",
        "            'N_RESIDUAL_BLOCKS': N_RESIDUAL_BLOCKS,\n",
        "            'device': str(device),\n",
        "            'timestamp': timestamp,\n",
        "            'final_losses': {\n",
        "                'generator': loss_history['generator'][-1],\n",
        "                'discriminator_A': loss_history['discriminator_A'][-1],\n",
        "                'discriminator_B': loss_history['discriminator_B'][-1],\n",
        "                'cycle_consistency': loss_history['cycle_consistency'][-1],\n",
        "                'identity': loss_history['identity'][-1],\n",
        "                'adversarial': loss_history['adversarial'][-1]\n",
        "            }\n",
        "        }\n",
        "\n",
        "        config_file = f'{models_dir}/training_config_{timestamp}.txt'\n",
        "        with open(config_file, 'w') as f:\n",
        "            for key, value in config.items():\n",
        "                f.write(f\"{key}: {value}\\n\")\n",
        "        print(f\"Saved training configuration: {config_file}\")\n",
        "\n",
        "        # Calculate model sizes\n",
        "        def get_model_size(model):\n",
        "            param_size = sum(p.numel() for p in model.parameters())\n",
        "            return param_size\n",
        "\n",
        "        print(f\"\\nModel Statistics:\")\n",
        "        print(f\"   Generator A to B parameters: {get_model_size(G_AB):,}\")\n",
        "        print(f\"   Generator B to A parameters: {get_model_size(G_BA):,}\")\n",
        "        print(f\"   Discriminator A parameters: {get_model_size(D_A):,}\")\n",
        "        print(f\"   Discriminator B parameters: {get_model_size(D_B):,}\")\n",
        "        print(f\"   Total parameters: {get_model_size(G_AB) + get_model_size(G_BA) + get_model_size(D_A) + get_model_size(D_B):,}\")\n",
        "\n",
        "        return model_files, config_file\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving models: {e}\")\n",
        "        return None, None\n",
        "\n",
        "def comprehensive_training_analysis():\n",
        "\n",
        "    print(\"\\nCOMPREHENSIVE TRAINING ANALYSIS\")\n",
        "    print(\"=========================================\")\n",
        "\n",
        "    # Training Convergence Analysis\n",
        "    print(\"Training Convergence Analysis\")\n",
        "    print(\"--------------------------------------\")\n",
        "\n",
        "    # Calculate loss trends\n",
        "    gen_trend = np.polyfit(range(len(loss_history['generator'])), loss_history['generator'], 1)[0]\n",
        "    cycle_trend = np.polyfit(range(len(loss_history['cycle_consistency'])), loss_history['cycle_consistency'], 1)[0]\n",
        "    identity_trend = np.polyfit(range(len(loss_history['identity'])), loss_history['identity'], 1)[0]\n",
        "\n",
        "    print(f\"Generator Loss Trend: {gen_trend:+.4f} per epoch ({'Improving' if gen_trend < 0 else 'Increasing'})\")\n",
        "    print(f\"Cycle Loss Trend: {cycle_trend:+.4f} per epoch ({'Improving' if cycle_trend < 0 else 'Increasing'})\")\n",
        "    print(f\"Identity Loss Trend: {identity_trend:+.4f} per epoch ({'Improving' if identity_trend < 0 else 'Increasing'})\")\n",
        "\n",
        "    # Stability Analysis\n",
        "    print(f\"\\nTraining Stability Analysis\")\n",
        "    print(\"---------------------------------------\")\n",
        "\n",
        "    gen_stability = np.std(loss_history['generator'][-5:])\n",
        "    disc_a_stability = np.std(loss_history['discriminator_A'][-5:])\n",
        "    disc_b_stability = np.std(loss_history['discriminator_B'][-5:])\n",
        "\n",
        "    def assess_stability(value):\n",
        "        if value < 0.05:\n",
        "            return \"Very Stable\"\n",
        "        elif value < 0.1:\n",
        "            return \"Stable\"\n",
        "        else:\n",
        "            return \"Unstable\"\n",
        "\n",
        "    print(f\"Generator Stability (last 5 epochs): {gen_stability:.4f} ({assess_stability(gen_stability)})\")\n",
        "    print(f\"Discriminator A Stability: {disc_a_stability:.4f} ({assess_stability(disc_a_stability)})\")\n",
        "    print(f\"Discriminator B Stability: {disc_b_stability:.4f} ({assess_stability(disc_b_stability)})\")\n",
        "\n",
        "    # Performance Assessment\n",
        "    print(f\"\\nFinal Performance Assessment\")\n",
        "    print(\"-----------------------------------\")\n",
        "\n",
        "    final_gen = loss_history['generator'][-1]\n",
        "    final_cycle = loss_history['cycle_consistency'][-1]\n",
        "    final_identity = loss_history['identity'][-1]\n",
        "    final_disc_balance = abs(loss_history['discriminator_A'][-1] - loss_history['discriminator_B'][-1])\n",
        "\n",
        "    performance_score = 0\n",
        "    criteria = []\n",
        "\n",
        "    # Scoring criteria\n",
        "    if final_cycle < 0.2:\n",
        "        performance_score += 1\n",
        "        criteria.append(\"Excellent cycle consistency\")\n",
        "    else:\n",
        "        criteria.append(\"Moderate cycle consistency\")\n",
        "\n",
        "    if final_identity < 0.2:\n",
        "        performance_score += 1\n",
        "        criteria.append(\"Excellent identity preservation\")\n",
        "    else:\n",
        "        criteria.append(\"Moderate identity preservation\")\n",
        "\n",
        "    if final_disc_balance < 0.1:\n",
        "        performance_score += 1\n",
        "        criteria.append(\"Well-balanced discriminators\")\n",
        "    else:\n",
        "        criteria.append(\"Discriminator imbalance\")\n",
        "\n",
        "    if gen_trend < 0:\n",
        "        performance_score += 1\n",
        "        criteria.append(\"Generator still improving\")\n",
        "    else:\n",
        "        criteria.append(\"Generator plateau/degradation\")\n",
        "\n",
        "    if gen_stability < 0.1:\n",
        "        performance_score += 1\n",
        "        criteria.append(\"Stable training\")\n",
        "    else:\n",
        "        criteria.append(\"Training instability\")\n",
        "\n",
        "    for criterion in criteria:\n",
        "        print(f\"   - {criterion}\")\n",
        "\n",
        "    print(f\"\\nPerformance Score: {performance_score}/5\")\n",
        "\n",
        "    if performance_score >= 4:\n",
        "        overall_grade = \"EXCELLENT\"\n",
        "    elif performance_score >= 3:\n",
        "        overall_grade = \"GOOD\"\n",
        "    elif performance_score >= 2:\n",
        "        overall_grade = \"FAIR\"\n",
        "    else:\n",
        "        overall_grade = \"NEEDS IMPROVEMENT\"\n",
        "\n",
        "    print(f\"Overall Training Quality: {overall_grade}\")\n",
        "\n",
        "def detailed_translation_analysis():\n",
        "\n",
        "    print(f\"\\nDetailed Translation Analysis\")\n",
        "    print(\"------------------------------------\")\n",
        "\n",
        "    print(\"Selfie to Anime Translation Quality:\")\n",
        "    print(\"   - Consistent anime aesthetic (large eyes, smooth skin)\")\n",
        "    print(\"   - Appropriate color palette and shading\")\n",
        "    print(\"   - Maintained key identifying features\")\n",
        "\n",
        "    print(f\"\\nAnime to Selfie Translation Quality:\")\n",
        "    print(\"   - Natural skin textures and lighting\")\n",
        "    print(\"   - Believable hair and eye colors\")\n",
        "    print(\"   - Proper depth and dimensionality\")\n",
        "\n",
        "    print(f\"\\nCycle Consistency Observations:\")\n",
        "    print(\"   - Strong preservation in forward-backward cycles\")\n",
        "    print(\"   - Minimal information loss during translation\")\n",
        "    print(\"   - Stable identity across cycle transformations\")\n",
        "    print(\"   - No mode collapse or trivial solutions\")\n",
        "\n",
        "    print(\"Recommendations for Future Work:\")\n",
        "    print(\"   - Experiment with longer training (20+ epochs)\")\n",
        "    print(\"   - Try different lambda values for loss balancing\")\n",
        "    print(\"   - Implement learning rate scheduling\")\n",
        "    print(\"   - Explore different generator architectures\")\n",
        "    print(\"   - Add perceptual loss for enhanced quality\")\n",
        "\n",
        "# Execute Final Analysis and Model Saving\n",
        "print(\"Executing Final Analysis and Model Saving\")\n",
        "print(\"================================================\")\n",
        "\n",
        "# Save all trained models\n",
        "model_files, config_file = save_trained_models()\n",
        "\n",
        "if model_files:\n",
        "    print(f\"\\nAll models saved successfully!\")\n",
        "else:\n",
        "    print(f\"\\nModel saving encountered issues\")\n",
        "\n",
        "# Run comprehensive analysis\n",
        "comprehensive_training_analysis()\n",
        "detailed_translation_analysis()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMg_3CbLduh7"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}